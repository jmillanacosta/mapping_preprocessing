# Workflow for downloading and saving Wikidata secondary2primary mappings
name: wikidata

on:
  workflow_dispatch:
  ##TODO: add schedule for deployment (suggestion: once a month?)
  
jobs:
  wikidata:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      # step 1: checkout the repository
    steps:
      - name: Download GitHub repo for the queries
        uses: actions/checkout@v3

      # step 2: run the SPARQL queries from the Wikidata query subfolder
      - name: Run the Queries
        run: |
          ## Download outdated IDs for chemicals
          curl -H "Accept: text/csv" --data-urlencode query@datasources/Wikidata/queries/chemicalRedirects.rq -G https://query.wikidata.org/sparql -o datasources/Wikidata/data/chemicalRedirectsWikidata.csv
          ## Download all primary IDs for chemicals
          curl -H "Accept: text/csv" --data-urlencode query@datasources/Wikidata/queries/chemicalAllPrimary.rq -G https://query.wikidata.org/sparql -o datasources/Wikidata/data/chemicalAllPrimaryWikidata.csv
          ## Download alias/synonyms/names for chemicals
          curl -H "Accept: text/csv" --data-urlencode query@datasources/Wikidata/queries/chemicalPrimarySynonyms.rq -G https://query.wikidata.org/sparql -o datasources/Wikidata/data/chemicalPrimarySynonymsWikidata.csv
      # step 3: save the data from the queries
      - name: Commit and Push Changes
        run: |
          git pull
          git add .
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git commit -m "Updating Wd data"
          git push
